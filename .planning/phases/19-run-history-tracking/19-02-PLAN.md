---
phase: 19-run-history-tracking
plan: 02
type: execute
wave: 2
depends_on: [19-01]
files_modified:
  - Tests/LabRunHistory.Tests.ps1
autonomous: true
requirements: [HIST-01, HIST-02, HIST-03]

must_haves:
  truths:
    - "Tests prove list mode returns last N runs sorted newest-first"
    - "Tests prove detail mode returns full run data for a specific RunId"
    - "Tests prove missing RunId throws a clear error"
    - "Tests prove corrupt artifact files are skipped with warning"
    - "Tests prove automatic logging produces expected artifact fields"
  artifacts:
    - path: "Tests/LabRunHistory.Tests.ps1"
      provides: "Pester 5 tests for Get-LabRunHistory"
      min_lines: 80
  key_links:
    - from: "Tests/LabRunHistory.Tests.ps1"
      to: "Public/Get-LabRunHistory.ps1"
      via: "dot-source in BeforeAll"
      pattern: "Get-LabRunHistory"
    - from: "Tests/LabRunHistory.Tests.ps1"
      to: "Private/Get-LabRunArtifactSummary.ps1"
      via: "dot-source in BeforeAll for helper dependency"
      pattern: "Get-LabRunArtifact"
---

<objective>
Create comprehensive Pester tests proving Get-LabRunHistory works correctly for list mode, detail mode, edge cases, and that the existing artifact logging produces the fields the requirements demand.

Purpose: Validate all three HIST requirements are met with automated tests.
Output: Tests/LabRunHistory.Tests.ps1 with passing Pester 5 tests.
</objective>

<execution_context>
@/home/anthonyscry/.claude/get-shit-done/workflows/execute-plan.md
@/home/anthonyscry/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-run-history-tracking/19-01-SUMMARY.md
@Public/Get-LabRunHistory.ps1
@Private/Get-LabRunArtifactSummary.ps1
@Tests/LabProfile.Tests.ps1
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Pester tests for Get-LabRunHistory</name>
  <files>Tests/LabRunHistory.Tests.ps1</files>
  <action>
Create Tests/LabRunHistory.Tests.ps1 following the established test pattern from Tests/LabProfile.Tests.ps1:

**BeforeAll block:**
- Set $repoRoot = Split-Path -Parent $PSScriptRoot
- Dot-source Public/Get-LabRunHistory.ps1
- Dot-source Private/Get-LabRunArtifactSummary.ps1 (contains Get-LabRunArtifactPaths, Get-LabLatestRunArtifactPath, Get-LabRunArtifactSummary)
- Define helper: New-TestLogRoot — creates a temp directory under TestDrive:\run-history-tests
- Define helper: Remove-TestLogRoot — removes the temp directory
- Define helper: New-TestRunArtifact — creates a realistic OpenCodeLab-Run-{runId}.json file in the test log root with fields: run_id, action, dispatch_mode, execution_outcome, requested_mode, effective_mode, started_utc, ended_utc, duration_seconds, success, error, host, user, events. Accept parameters: $LogRoot, $RunId, $Action (default 'deploy'), $Success (default $true), $DurationSeconds (default 30), $EndedUtc (default current time ISO 8601)

**Describe 'Get-LabRunHistory' with the following test contexts:**

Context 'List mode':
1. Returns empty array when log directory has no artifacts
2. Returns summary objects with expected properties (RunId, Action, Mode, Success, DurationSeconds, EndedUtc, Error)
3. Returns results sorted newest-first (create 3 artifacts with different EndedUtc, verify order)
4. Respects -Last parameter (create 5 artifacts, request -Last 2, verify count is 2)
5. Skips .txt files (only processes .json)

Context 'Detail mode':
6. Returns full run data when -RunId matches an artifact
7. Returns object with all expected fields (run_id, action, started_utc, ended_utc, duration_seconds, success, events, host, user)
8. Throws when -RunId does not match any artifact

Context 'Error handling':
9. Skips corrupt JSON files with Write-Warning (create a file with invalid JSON content, verify list mode still works and returns remaining valid entries)
10. Returns empty array when LogRoot directory does not exist (or handles gracefully)

**Each test uses try/finally with Remove-TestLogRoot for cleanup (matching profile test pattern).**

Run `pwsh -Command "Invoke-Pester Tests/LabRunHistory.Tests.ps1 -Output Detailed"` to verify all tests pass.
  </action>
  <verify>Run: pwsh -Command "Invoke-Pester Tests/LabRunHistory.Tests.ps1 -Output Detailed" — all tests should pass (10+ tests, 0 failures).</verify>
  <done>Tests/LabRunHistory.Tests.ps1 exists with 10+ Pester 5 tests covering list mode, detail mode, sorting, -Last filtering, error handling, and corrupt file resilience. All tests pass.</done>
</task>

</tasks>

<verification>
- Tests/LabRunHistory.Tests.ps1 exists
- All Pester tests pass with 0 failures
- Tests cover HIST-01 (artifact field validation), HIST-02 (list mode), HIST-03 (detail mode)
- Tests follow project patterns: BeforeAll dot-source, try/finally cleanup, TestDrive usage
</verification>

<success_criteria>
All Pester tests pass. Test coverage proves: list mode returns summary table with correct fields, detail mode returns full run data, corrupt files are handled gracefully, and the artifact format contains timestamp, action, outcome, and duration as required by HIST-01.
</success_criteria>

<output>
After completion, create `.planning/phases/19-run-history-tracking/19-02-SUMMARY.md`
</output>
